## 소프트 파싱 vs 하드 파싱

> [!note] 라이브러리 캐시
> 내부 프로시저를 반복 재사용할 수 있도록 캐싱해 두는 메모리 공간

> [!note] SGA(System Global Area)
> 서버 프로세스와 백그라운드 프로세스가 공통으로 엑세스하는 데이터와 제어 구조를 캐싱하는 메모리 공간

### 소프트 파싱
SQL을 캐시에서 찾아 곧바로 실행단계로 넘어가는 것
### 하드 파싱
찾는 데 실패해 최적화 및 로우 소스 생성 단계까지 모두 거치는 것

> [!note]
> 데이터베이스에서 이루어지는 처리 과정은 대부분 I/O 작업에 집중되는 반면, 하드 파싱은 CPU를 많이 소비하는 몇 안 되는 작업 중 하나다.

## 바인드 변수의 중요성

사용자 정의 함수/프로시저, 트리거, 패키지 등은 생성할 때부터 이름을 갖는다. 컴파일한 상태로 딕셔너리에 저장되며, 사용자가 삭제하지 않는 한 영구적으로 보관된다.
실행할 때 라이브러리 캐시에 적재함으로써 여러 사용자가 공유하면서 재사용한다.

반면, SQL은 이름이 따로 없다. 전체 SQL 텍스트가 이름 역할을 한다.

DBMS에서 수행되는 SQL이 모두 완성된 SQL은 아니며, 특히 개발 과정에는 수시로 변경이 일어난다. 일회성(ad hoc) SQL도 많다. 일회성 또는 무효화된 SQL까지 모두 저장하려면 많은 공간이 필요하고, 그만큼 SQL을 찾는 속도도 느려진다. 오라클, SQL Server 같은 DBMS가 SQL을 영구저장하지 않는 쪽을 선택한 이유다.

500만 고객을 보유한 어떤 쇼핑몰에서 다음과 같이 작성했다고 하자.
```java
public void login(String login_id) throws Exception {
	String SQLStmt = "SELECT * FROM CUSTOMER WHERE LOGIN_ID = '" + login_id + "'";
	Statement st = con.createStatement();
	ResultSet rs = st.executeQuery(SQLStmt);
	if (rs.next()) {
		// do anything
	}
	rs.close();
	st.close();
}
```
이 쇼핑몰에서 어느 날 12시 정각부터 딱 30분간 대대적인 할인 이벤트를 하기로 했다. 500만 명 중 20%에 해당하는 100만 고객이 이벤트 당일 12시를 전후해 동시에 시스템 접속을 시도할 경우 어떤 일이 발생할까?

DBMS에 발생하는 부하는 대개 과도한 I/O가 원인인데, 이날은 I/O가 거의 발생하지 않음에도 불구하고 CPU 사용률은 급격히 올라가고, 라이브러리 캐시에 발생하는 여러  종류의 경합 때문에 로그인이 제대로 처리되지 않을 것이다.
이는 각 고객에 대해 동시다발적으로 발생하는 SQL 하드파싱 때문이다.

그 순간 라이브러리 캐시(V$SQL)를 조회해 보면, 아래와 같은 SQL로 가득 차 있다.
```sql
SELECT * FROM CUSTOMER WHERE LOGIN_ID = 'oraking'
SELECT * FROM CUSTOMER WHERE LOGIN_ID = 'javaking'
SELECT * FROM CUSTOMER WHERE LOGIN_ID = 'tommy'
SELECT * FROM CUSTOMER WHERE LOGIN_ID = 'karajan'
...
```

로그인 프로그램을 이렇게 작성하면, 고객이 로그인 할 때마다 아래와 같이 DBMS 내부 프로시저를 하나씩 만들어서 라이브러리 캐시에 적재하는 셈이다.
```sql
create procedure LOGIN_ORAKING( ) { ... }
create procedure LOGIN_JAVAING( ) { ... }
create procedure LOGIN_TOMMY( ) { ... }
create procedure LOGIN_KARAJAN( ) { ... }
...
```
위 프로시저의 내부 처리 루틴은 모두 같다. 그렇다면 프로시저를 여러 개 생성할 것이 아니라 아래처럼 로그인 ID를 파라미터로 받는 프로시저 하나를 공유하면서 재사용하는 것이 마땅하다.
```sql
create procedure LOGIN (login_id in varchar2) { ... }
```
이처럼 파라미터 Driven 방식으로 SQL을 작성하는 방법이 저공되는데, 바인드 변수가 바로 그것이다.

```java
public void login(String login_id) throws Exception {
	String SQLStmt = "SELECT * FROM CUSTOMER WHERE LOGIN_ID = ?";
	PreparedStatement st = con.prepareStatement(SQLStmt);
	st.setString(1, login_id);
	ResultSet rs = st.executeQuery();
	if (rs.next()) {
		// do anything
	}
	rs.close();
	st.close();
}
```
이 순간 라이브러리 캐시를 조회해 보면, 로그인과 관련해서 아래 SQL 하나만 발견된다.
```sql
SELECT * FROM CUSTOMER WHERE LOGIN_ID = :1
```

## SQL이 느린 이유

SQL이 느린 이유는 십중팔구 I/O 때문이다. 구체적으로 말해, **디스크 I/O** 때문이다.

## 데이터베이스 저장 구조

- 블록: 데이터를 읽고 쓰는 단위
- 익스텐트: 공간을 확정하는 단위. 연속된 블록 집합
- 세그먼트: 데이터 저장공간이 필요한 오브젝트(테이블, 인덱스, 파티션, LOB 등)
- 테이블스페이스: 세그먼트를 담는 콘테이너
- 데이터 파일: 디스크 상의 물리적인 OS 파일

> [!note] DBA(Data Block Address)
> 모든 데이터 블록은 디스크 상에서 몇 번 데이터파일의 몇 번째 블록인지를 나타내는 자신만의 고유 주소값을 갖는다. 이 주소값을 'DBA(Data Block Address)'라고 부른다. 데이터를 읽고 쓰는 단위가 블록이므로 데이터를 읽으려면 먼저 DBA부터 확인해야 한다.
> 
> 인덱스를 이용해 테이블 레코드를 읽을 때는 인덱스 ROWID를 이용한다. ROWID는 DBA + 로우 번호(블록 내 순번)로 구성되므로 이를 분해하면 읽어야 할 테이블 레코드가 저장된 DBA를 알 수 있다.
>
> 테이블을 스캔할 때는 테이블 세그먼트 헤더에 저장된 익스텐트 맵을 이용한다. 익스텐트 맵을 통해 각 익스텐트의 첫 번째 블록 DBA를 알 수 있다. 익스텐트는 연속된 블록 집합이므로 테이블을 스캔할 때는 첫 번째 블록 뒤에서 연속해서 저장된 블록을 읽으면 된다.

## 블록단위 I/O

**블록**은 DBMS가 데이터를 읽고 쓰는 단위이다.
데이터 I/O 단위가 블록이므로 **특정 레코드 하나를 읽고 싶어도 해당 블록을 통째로 읽는다**. 심지어 1Byte짜리 컬럼 하나만 읽고 싶어도 블록을 통째로 읽는다.
> 오라클은 기본적으로 8KB 크기의 블록을 사용하므로 1Byte를 읽기 위해 8KB를 읽는 셈이다.

또한, 테이블 뿐만 아니라 인덱스도 블록 단위로 데이터를 읽고 쓴다.

## 시퀀셜 액세스 vs 랜덤 액세스

### 시퀀셜 액세스
논리적 또는 물리적으로 연결된 순서에 따라 차례대로 블록을 읽는 방식이다.

인덱스 리프 블록은 앞뒤를 가리키는 주소값을 통해 논리적으로 서로 연결돼 있다. 이 주소 값에 따라 앞 또는 뒤로 순차적으로 스캔하는 방식이 시퀀셜 액세스다.

하지만 테이블 블록 같에는 서로 논리적인 연결고리를 갖고 있지 않다. 그럼, 테이블은 어떻게 시퀀셜 방식으로 액세스할까?
오라클은 세그먼트에 할당된 **익스텐트 목록을 세그먼트 헤더에 맵(map)으로 관리한다**. 익스텐트 맵은 **각 익스텐트의 첫 번째 블록 주소 값**을 갖는다. 읽어야 할 익스텐트 목록을 익스텐트 맵에서 얻고, 각 익스텐트의 첫 번째 블록 뒤에 연속해서 저장된 블록을 순서대로 읽으면, 그것이 곧 **Full Table Scan**이다.

### 랜덤 액세스
논리적, 물리적인 순서를 따르지 않고, 레코드 하나를 읽기 위해 한 블록씩 접근하는 방식이다.

## 논리적 I/O vs 물리적 I/O

### DB 버퍼캐시
**디스크 I/O가 SQL 성능을 결정**하기 때문에 자주 읽는 블록을 매번 디스크에서 읽는 것은 매우 비효율적이다.
모든 DBMS에 데이터 캐싱 메커니즘이 필수인 이유다.

라이브러리 캐시말고도 데이터를 캐싱하는 **DB 버퍼캐시**도 SGA의 가장 중요한 구성요소 중 하나다.

라이브러리 캐시가 SQL과 실행계획, DB 저장형 함수/프로시저 등을 캐싱하는 '코드 캐시'라고 한다면, DB 버퍼캐시는 '데이터 캐시'라고 할 수 있다. 디스크에서 어렵게 읽은 **데이터 블록을 캐싱해 둠으로써 같은 블록에 대한 반복적인 I/O Call을 줄이는 데 목적**이 있다.

서버 프로세스와 데이터파일 사이에 버퍼캐시가 있으므로 데이터 블록을 읽을 땐 항상 버퍼캐시부터 탐색한다. 버퍼캐시는 공유메모리 영역이므로 같은 블록을 읽는 다른 프로세스도 득을 본다.

### 논리적 I/O
논리적 블록 I/O는 **SQL 문을 처리하는 과정에 메모리 버퍼캐시에서 발생한 총 블록 I/O**를 말한다. 
Direct Path I/O가 작동하는 경우가 있으므로 논리적 I/O와 메모리 I/O가 정확히 같은 의미는 아니지만, 일반적으로 같다고 생각해도 무방하다.

> [!note] Direct Path I/O
> 버퍼 캐시를 경유하지 않고 곧바로 데이터 블록을 읽고 쓸 수 있는 기능이다.
> 일반적으로 I/O 성능을 향상시키기 위해 버퍼 캐시를 경유한다. 하지만 대용량 데이터를 읽고 쓰거나 재사용 가능성이 없는 임시 세그먼트 블록들을 읽고 쓸 때는 버퍼 캐시를 경유하지 않는 것이 유리하다. 때문에 오라클은 버퍼 캐시를 경유하지 않고 곧바로 데이터 블록을 읽고 쓸 수 있는 Direct Path I/O 기능을 제공한다.

### 물리적 I/O
물리적 블록 I/O는 디스크에서 발생한 총 블록 I/O를 말한다.
SQL 처리 도중 읽어야 할 블록을 버퍼캐시에서 찾지 못할 때만 디스크를 액세스하므로 논리적 블록 I/O 중 일부를 물리적으로 I/O한다.

### 버퍼캐시 히트율
버퍼캐시 효율을 측정하는 데 전통적으로 가장 많이 사용해온 지표는 버퍼캐시 히트율(Buffer Cache Hit Ratio, BCHR)이다.

BCHR = (캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수 ) * 100
       = ( (논리적 I/O - 물리적 I/O) / 논리적 I/O) * 100
       = ( 1- 물리적 I/O / 논리적 I/O) * 100

어플리케이션 특성에 따라 다르지만, 온라인 트랜잭션을 주로 처리하는 어플리케이션이라면 시스템 레벨에서 평균 99% 히트율을 달성해야 한다. 핵심 트랜잭션이 시스템 전체 부하의 대부분을 차지하므로 열심히 튜닝하면 99%는 결코 달성하기 어려운 수치가 아니다.

BCHR 공식에서 중요한 성능 원리를 발견할 수 있다. 물리적 I/O가 성능을 결정하지만, 실제 SQL 성능을 향상하려면 물리적 I/O가 아닌 논리적 I/O를 줄여야 한다는 사실이다.
BCHR 공식을 아래와 같이 변형하면, 쉽게 알 수 있다.

$$ 물리적 I/O = 논리적 I/O \times (100 - BCHR)  $$
논리적 I/O는 일정하므로 물리적 I/O는 BCHR에 의해 결정된다. BCHR은 시스템 상황에 따라 달라지므로 물리적 I/O는 결국 시스템 상황에 의해 결정되는 통제 불가능한 외생변수다.
SQL 성능을 높이기 위해서 할 수 있는 일은 논리적 I/O를 줄이는 일뿐이다. 예를 들어, 시스템 레벨 BCHR이 평균 70%라고 할 대, 특정 SQL의 논리적 I/O가 10,000개면 물리적 I/O는 대략 3,000개쯤 발생할 것으로 예상할 수 있다.
여기서 논리적 I/O를 1,000개로 줄이면 물리적 I/O도 300으로 감소하고, 성능도 열 배 향상된다.