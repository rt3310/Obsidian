## 캐시 종류

- 로컬캐시 (EHcache)
- DB 내부 캐시
- CDN
- 웹캐시
- in-memory 캐시 (redis, memcached)


## 캐시 비교

### 로컬 캐시
##### 장점
- 타 서버간 통신 비용이 발생하지 않는다.
- 서버 인스턴스 메모리 저장하기 때문에 가져오는데 속도가 빠르다.
##### 단점
- 서버가 여러 대로 클러스터링 되어 있는 경우, 동기화가 되지 않는다.
- 캐시 데이터가 커질수록 서버 메모리가 부족해지며 이에 따라 애플리케이션 성능이 저하될 수 있다.

### Redis
데이터 영속성을 지원하는 In-memory 저장소 (스냅샷 기능을 통해 Disk에 캐시데이터를 저장할 수 있기 때문)
##### 장점
- 서버 복제 지원, Master-slave 구조로 여러 대의 복제본을 만들 수 있다.
- 트랜잭션 지원
- 여러 데이터 자료형 지원(문자열, 숫자, boolean 등)
##### 단점
- 싱글스레드로 동작하기 때문에 병목현상이 발생할 수 있다.
- 로컬 캐시에 비해 서버 ↔︎ redis 간 통신 비용이 발생한다.

### 웹 캐시
웹 사용자에 의해 빈번히 요청되는 데이터를 우베캐시 서버(Nginx 등)에 보관함으로써 응답한다.
- Client - Nginx proxy server - Server 구조 일 때, 요청이 nginx 서버에 캐시되어 있다면 실제 요청은 Server에 전달되지 않고 Client에게 반환된다.
##### 장점
- 요청이 실제 서버로 넘어가지 않기 때문에 부하 자체를 줄여줄 수 있다.
##### 단점
- 별도의 웹캐시용의 서버 구성 필요
- Client에서 Server로 요청하는 과정에 Proxy 서버가 중간에 끼게 되는 형태인데, 통신 과정이 늘어나니까 당연히 소요시간이 길어질 수 있다.

## 로컬 캐시 비교

### Ehcache
- 가장 널리 사용되는 JAVA 기반 캐시
- 직렬화된 데이터 객체를 저장하는 메모리 블럭
- 3개의 스토리지 저장 가능 (메모리 / off Heap(GC 적용하지 않아 매우 큰 캐시 생성 가능)/ 디스크)
![](https://miro.medium.com/v2/resize:fit:1400/1*2Lfh6ISU-OWWD66kXGV5xw.png)
- LRU / LFU / FIFO 제거 알고리즘 제공

### Caffeine cache
- high performance + 최적의 캐싱 라이브러리라고 소개 (어떤 곳은 극단적으로 local cache의 king이라고 표현 과연?)
- Google 오픈 소스 Guava Cache / ConcurrentLinkedHashMap 을 바탕으로 만들어짐
- 캐시 제거 전략에 우선순위를 부여 가능
- 최적의 적중률을 제공하는 [Window TinyLfu](https://dgraph.io/blog/refs/TinyLFU%20-%20A%20Highly%20Efficient%20Cache%20Admission%20Policy.pdf) 제거 정책 사용

Caffeine cache를 보다 잘 이해하기 위해서는 eviction 정책을 좀 더 이해를 해야 하는데요.

아래의 eviction 동작 원리를 간략히 보면
![](https://miro.medium.com/v2/resize:fit:920/1*GhabPsotTpyLR9JINNKrLg.png)
![](https://miro.medium.com/v2/resize:fit:1400/1*84pKiujtGOpbnpVgIwhpkQ.png)

Main Cache (전체 용량 99%)
- Probation Cache(공간 80%)-자주 사용하는 데이터(제거 시 LRU rule 적용)
- Protected Cache(공간 20%)-자주 사용하지 않는 데이터 (제거되지 않음)

Window Cache (전체 용량 1%)
- 새로운 데이터가 Cache에 쓰일 때 가장 먼저 Window Cache에 쓰임
- 공간에 가득 찰 경우 LRU 식으로 Window Cache 밖으로 제거 (LRU)
- — Tiny LFU 알고리즘에 의해 제거되거나 Probation Cache 영역에 저장됨
- Probation 영역 데이터에 일정한 횟수 이상 접근되면 Protected Cache 역으로 승격됨
- — Protected Cache 영역이 Full 될 경우 오래된 데이터 밖으로 옮겨짐
- — — TinyLFU 알고리즘에 의해 제거되거나 Probation Cache 영역에 저장됨

[**TinyLFU 제거 메커니즘**](https://www.sobyte.net/post/2022-04/caffeine/)
- Window Cache / Protected Cache로부터 제거되는 데이터 = Candidate
- Probation Cache에서 제거되는 데이터 = Victim
- Candidate Cache 접근 > Victim Cache 접근 : Victim 데이터 제거
- Candidate Cache 접근 < Victim Cache 접근 && Candidate 접근 횟수 5번 이하 : Candidate 데이터 제거
- 둘 중 하나 랜덤하게 제거

Caffeine 캐시 내부 알고리즘은 LFU와 LRU의 장점을 통합
- 서로 다른 캐시 영역에 다른 특성을 가진 캐시 항목을 저장하여 최근에 생성된 캐시 데이터가 Window Cache로 들어가 삭제되지 않음
- 자주 호출되는 데이터 (LFU)은 Protected 영역에 들어가며 LRU에 의해 제거되지 않음
- 호출 횟수 / 호출 시간 두 개의 자원에 대해 밸런스가 잘 되어 있음
- — 자주 호출되고 최근에 생성된 데이터 들은 가능한 캐시에 유지 시킬수 있음
- 전통적인 LRU/LFU 로 처리 할 수 없던 케이스를 보다 잘 처리함

## 캐시를 사용하기 적절한 데이터인지 판단하는 기준

- 데이터가 변경에 민감한지?
- 데이터의 연산에 드는 비용이 비싼지?
- 데이터의 변경이 전파가 되는지?
- 요약하자면, “**잘 바뀌지 않으면서 접근할 일이 많은 데이터**, 변경되더라도 다른 서비스에 큰 영향을 미치지 않는 데이터” 가 캐시에 저장하여 활용하기 적절하다.